---
title: "Using cTWAS"
author: "wesleycrouse"
date: "2023-08-31"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Overview

This document is a user guide for the cTWAS R package. It details how to use to use the summary statistics version of cTWAS, which is an integrative method for identifying causal genes at GWAS loci using eQTL data. Briefly, cTWAS conditions on genetic confounders, jointly modeling sparse effects of all nearby genes and variants in an extended fine-mapping framework. Additional details are available in the [paper](https://doi.org/10.1101/2022.09.27.509700). 

Running cTWAS involves four main steps: preparing input data, imputing gene z-scores, estimating parameters, and fine-mapping the genes and variants. The output of cTWAS is a posterior inclusion probability (PIP) for each variant and each gene with an expression model. This document will cover each of these topics in detail. We also describe some of the options available at each step and the analysis considerations behind these options. 

We will start by examining the input data and running the cTWAS fine-mapping step at a single locus using parameters previously estimated in the cTWAS paper. Running cTWAS with fixed parameters at a single locus is relatively fast, and is the simplest way to use cTWAS, but it requires specifying parameters, rather than learning them from the data. 

We will then provide a workflow for the same analysis, but using the full data and estimating parameters. This can be computationally intensive. We performed these analyses for the paper with 10 cores and 56GB of RAM, although the exact resource requirements will vary with the numbers of genes and variants provided.

## Getting started

Start by installing cTWAS in R via GitHub. For the first section of this document, we will use the main branch of cTWAS.

```{r, eval=F}

remotes::install_github("xinhe-lab/ctwas", ref = "main")

```

Then load the package and set the working directory where you want to perform perform the analysis.

```{r}

library(ctwas)

#set the working directory interactively
#setwd("/project2/mstephens/wcrouse/ctwas_tutorial")

#set the working directory when compiling this document with Knitr
#knitr::opts_knit$set(root.dir = "/project2/mstephens/wcrouse/ctwas_tutorial")

```

## Preparing input data

The inputs for the summary statistics version of cTWAS include GWAS summary statistics for variants, prediction models for genes, and an LD reference. These inputs should be harmonized prior to analysis because the reference and alternative alleles for each variant may not  match across GWAS summary statistics, prediction model for genes and LD reference.

We provide some options for harmonization if the data are not already harmonized. For example, if variants that are not strand ambiguous, harmonization simply flips reference and alternative alleles to match the LD reference. Please see the topics on harmonization for more details.

The LD reference should contain as many of the GWAS and eQTL variants as possible. Only variants in both the GWAS and LD reference are included in the analysis. Further, if a variant is in the prediction models but not the LD reference or the GWAS, it cannot be used for imputation. We recommend imputing z-scores for variants missing from the GWAS but in the LD reference, and taking care to ensure overlap between the variants in the LD reference and the prediction models.


### GWAS z-scores

For this analysis, we will use summary statistics from a GWAS of LDL cholesterol in the UK Biobank. We will download the VCF from the IEU Open GWAS Project. Set the working directory, download the summary statistics, and unzip the file.

```{r, eval=F}

dir.create("/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats")

system("wget https://gwas.mrcieu.ac.uk/files/ukb-d-30780_irnt/ukb-d-30780_irnt.vcf.gz -P gwas_summary_stats")
R.utils::gunzip("/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.vcf.gz")

```

Next, we will use the VariantAnnotation package to read the summary statistics. Then, we will compute the z-scores and format the input data. We will also collect the sample size, which will be useful later. We will save this output for convenience.

```{r, eval=F}
#read the data
z_snp <- VariantAnnotation::readVcf("/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.vcf")
z_snp <- as.data.frame(gwasvcf::vcf_to_tibble(z_snp))

#compute the z-scores
z_snp$Z <- z_snp$ES/z_snp$SE

#collect sample size (most frequent sample size for all variants)
gwas_n <- as.numeric(names(sort(table(z_snp$SS),decreasing=TRUE)[1]))

#subset the columns and format the column names
z_snp <- z_snp[,c("rsid", "ALT", "REF", "Z")]
colnames(z_snp) <- c("id", "A1", "A2", "z")

#drop multiallelic variants (id not unique)
z_snp <- z_snp[!(z_snp$id %in% z_snp$id[duplicated(z_snp$id)]),]

#save the formatted z-scores and GWAS sample size
saveRDS(z_snp, file="/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.RDS")
saveRDS(gwas_n, file="/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/gwas_n.RDS")

```

After the previous step has run, we can load the data and look at the format. Z_snp is a data frame, and each row is a variant. A1 is the alternate allele, and A2 is the reference allele. The sample size for this GWAS is N=343,621.

```{r}

z_snp <- readRDS("/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt.RDS")
gwas_n <- readRDS("/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/gwas_n.RDS")

head(z_snp)
gwas_n

```

If your GWAS summary statistics is of other formats, extracting relevant columns (rsid, alternative allele, reference allele, zscore) and converting it to the format shown above.

### Prediction models

Prediction models can be specified in either PredictDB or FUSION format. Given a choice, PredictDB is the recommended format as some optional features are not implemented for FUSION. PredictDB has covariance information among SNPs included in the model, which can be used to recover strand ambiguous variants. In this user guide, we focus on the PredictDB format, but will provide information on using FUSION format.

Note: cTWAS performs best when prediction models are sparse (i.e. they do not include many variants per gene). As the density of variants increases, it becomes more intensive to compute gene-by-gene correlations using summary statistics. Dense variants can also lead to excessive region merging. See the topics on region merging for more details. Given an option, it is preferable to choose sparse prediction models for these reasons. If using dense prediction models, we recommend removing variants with weight below a threshold from the prediction models.

#### PredictDB format

Please check [PredictDB](http://predictdb.org/) for the format of PredictDB weights. To specify weights in PredictDB format, provide the path to the `.db` file. 

For this analysis, we will use liver gene expression models trained on GTEx v8 in the PredictDB format. We will download both the prediction models (`.db`) and the covariances between variants in the prediction models (`.txt.gz`). The covariances can optionally be used during harmonization to recover strand ambiguous variants.

```{r, eval=F}

#download the files
system("wget https://zenodo.org/record/3518299/files/mashr_eqtl.tar")

#extract to ./weights folder 
system("mkdir /project2/xinhe/shared_data/ctwas_tutorial/weights")
system("tar -xvf mashr_eqtl.tar -C /project2/xinhe/shared_data/ctwas_tutorial/weights")
system("rm mashr_eqtl.tar")

```

In the paper, we used PredictDB models for liver gene expression. We also performed an additional preprocessing step to remove lncRNAs from the prediction models. This can be done using the following code:

```{r}

library(RSQLite)

#specify the weight to remove lncRNA from
weight <- "/project2/xinhe/shared_data/ctwas_tutorial/weights/eqtl/mashr/mashr_Liver.db"

#read the PredictDB weights
sqlite <- dbDriver("SQLite")
db = dbConnect(sqlite, weight)
query <- function(...) dbGetQuery(db, ...)
weights_table <- query("select * from weights")
extra_table <- query("select * from extra")
dbDisconnect(db)

#subset to protein coding genes only
extra_table <-  extra_table[extra_table$gene_type=="protein_coding",,drop=F]
weights_table <- weights_table[weights_table$gene %in% extra_table$gene,]

#read and subset the covariances
weight_info = read.table(gzfile(paste0(tools::file_path_sans_ext(weight), ".txt.gz")), header = T)
weight_info <- weight_info[weight_info$GENE %in% extra_table$gene,]

#write the .db file and the covariances
dir.create("weights_nolnc", showWarnings=F)

if (!file.exists("/project2/xinhe/shared_data/ctwas_tutorial/weights_nolnc/mashr_Liver_nolnc.db")){
  db <- dbConnect(sqlite, "weights_nolnc/mashr_Liver_nolnc.db")
  dbWriteTable(db, "extra", extra_table)
  dbWriteTable(db, "weights", weights_table)
  dbDisconnect(db)

  weight_info_gz <- gzfile("/project2/xinhe/shared_data/ctwas_tutorial/weights_nolnc/mashr_Liver_nolnc.txt.gz", "w")
  write.table(weight_info, weight_info_gz, sep=" ", quote=F, row.names=F, col.names=T)
  close(weight_info_gz)
}

#specify the weight for the analysis
weight <- "/project2/xinhe/shared_data/ctwas_tutorial/weights_nolnc/mashr_Liver_nolnc.db"

```

#### FUSION format

Please check [Fusion/TWAS](http://gusevlab.org/projects/fusion/#compute-your-own-predictive-models) for the format of FUSION weights. Below is an example.

```{r}

weight_fusion <- system.file("extdata/example_fusion_weights", "Tissue", package = "ctwas")

```

To specify weights in FUSION format, provide the directory that contains all the `.rdata` files as above. We assume a file with the same name as the directory with the suffix `.pos` is present in the same level as the directory. The program will search for this file automatically. For example, we have both the directory `Tissue/` and `Tissue.pos` present under the `extdata/example_fusion_weights` folder. Note that FUSION weights don’t come with covariance information among variants. So you need to turn off the option “recover_strand_ambig_wgt”

```{r}

#directory and .pos file
list.files(dirname(weight_fusion))

#.rda files
list.files(weight_fusion)

rm(weight_fusion)

```

### LD reference and regions

LD reference information can be provided to cTWAS as either individual-level genotype data (in PLINK format), or as genetic correlation matrices (termed "R matrices") for regions that are approximately LD-independent. These regions must also be specified, regardless of how the LD reference information is provided.

cTWAS performs its analysis region-by-region. If individual-level genotype data is used for the LD reference, variants are assigned to regions, and then correlations matrices are computed within each region. This can be computationally expensive if there are many individuals or if variants in the LD reference are dense. For this reason, the preferred way to run cTWAS is to provide pre-computed LD matrices for each region. 

It is critical that the genome build (e.g. hg38) of the LD reference matches the genome build used to train the prediction models. The genome build of the GWAS summary statistics does not matter because variant positions are determined by the LD reference.

The choice of LD reference population is important for fine-mapping. Best practice for fine-mapping is to use an in-sample LD reference (LD computed using the subjects in the GWAS sample). If an in-sample LD reference is not an option, the LD reference should be as representative of the population in the GWAS sample as possible. Given that cTWAS is an extended fine-mapping algorithm, and that gene z-scores are computed using the observed GWAS z-scores, which reflect patterns of LD in the GWAS population, our recommendation is to match the LD reference to the GWAS population, not the population used to build the prediction models. 

#### Regions

cTWAS includes pre-defined regions based on European (EUR), Asian (ASN), or African (AFR) populations, using either genome build b38 or b37. These regions were previously generated using LDetect. These regions are specified in `ctwas_rss` function using the `ld_regions` and `ld_regions_version` arguments, respectively. The regions are left closed and right open, i.e. [start, stop). We will open the b38 European region file, which is included in the package, to view the format, centered on the region that we will analyze later.

```{r}

regions <- system.file("extdata/ldetect", "EUR.b38.bed", package = "ctwas")

regions_df <- read.table(regions, header = T)

locus_chr <- "chr16"
locus_start <- 71020125

regions_df[which(regions_df$chr==locus_chr & regions_df$start==locus_start)+c(-2:2),]

rm(regions)

```

Note that the default behavior of cTWAS is to merge regions that have a gene spanning the region boundary (`merge=T`). For this reason, the regions specified here may not correspond exactly to the final regions analyzed by cTWAS. See the section on region merging for more details.

It is also possible to specify custom regions using `ld_regions_custom` in `.bed` format. We will make a custom region file that includes only the region containing the HPR locus that we analyzed in the paper.

```{r}

regions_df <- regions_df[regions_df$chr==locus_chr & regions_df$start==locus_start,]

dir.create("/project2/xinhe/shared_data/ctwas_tutorial/regions", showWarnings=F)
regions_file <- "/project2/xinhe/shared_data/ctwas_tutorial/regions/regions_subset.bed"
write.table(regions_df, file=regions_file, row.names=F, col.names=T, sep="\t", quote = F)

rm(regions_df)

```

#### Genotypes

To use individual genotypes for the LD reference, provide a character vector of `.pgen` or `.bed` files. There should be one file per chromosome, ordered from 1 to 22. If `.pgen` files are specified, then `.pvar` and `.psam` files must also be in the same directory. If `.bed` files are specified, then `.bim` and `.fam` files must also be in the same directory. We include an example here:

```{r}

ld_pgenfs <- system.file("extdata/example_genotype_files", paste0("example_chr", 1:22, ".pgen"), package = "ctwas")
head(ld_pgenfs)
rm(ld_pgenfs)

```

#### LD matrices

To use LD matrices for the LD reference, provide a directory containing all of the `.RDS` matrix files and matching `.Rvar` variant information files. We have included an LD matrix for the HPR locus that we analyzed in the paper as part of the package. The complete LD matrix for this region was too large to include in the package, so we include only half of the variants at this locus, including the ones needed for the prediction models at this locus. We obtained the example LD matrix using the following code:

```{r, eval=F}
R_snp <- readRDS("/project2/mstephens/wcrouse/UKB_LDR_0.1/ukb_b38_0.1_chr16.R_snp.71020125_72901251.RDS")
R_snp_info <- read.table("/project2/mstephens/wcrouse/UKB_LDR_0.1/ukb_b38_0.1_chr16.R_snp.71020125_72901251.Rvar", header=T)

set.seed(3724598)
keep_index <- as.logical(rbinom(nrow(R_snp_info), 1 ,0.5)) | R_snp_info$id %in% weights_table$rsid

R_snp_info <- R_snp_info[keep_index,]
R_snp <- R_snp[keep_index, keep_index]

saveRDS(R_snp, file="/project2/xinhe/shared_data/ctwas_tutorial/example_locus_chr16.R_snp.71020125_72901251.RDS")
write.table(R_snp_info, file="/project2/xinhe/shared_data/ctwas_tutorial/example_locus_chr16.R_snp.71020125_72901251.Rvar", sep="\t", col.names=T, row.names=F, quote=F)

rm(R_snp, R_snp_info)

```

This LD matrix can be loaded directly from the package:

```{r}

ld_R_dir <- system.file("extdata/ld_matrices", package = "ctwas")
list.files(ld_R_dir)

```

The `.RDS` file is [R .RDS format](https://www.rdocumentation.org/packages/base/versions/3.3.2/topics/readRDS?tap_a=5644-dce66f&tap_s=10907-287229). It stores the LD correlation matrix for a region (a $p \times p$ matrix, $p$ is the number of variants in the region). We require that for each `.RDS` file, in the same directory, there is a corresponding file with the same stem but ending with the suffix `.Rvar`. This `.Rvar` files includes variant information for the region, and the order of its rows must match the order of rows and columns in the `.RDS` file. The format of these files is:

```{r}

#correlation matrix
R_snp <- readRDS(system.file("extdata/ld_matrices", "example_locus_chr16.R_snp.71020125_72901251.RDS", package = "ctwas"))
str(R_snp)
R_snp[1:5,1:5]

#variant info
R_snp_info <- read.table(system.file("extdata/ld_matrices", "example_locus_chr16.R_snp.71020125_72901251.Rvar", package = "ctwas"), header=T)
head(R_snp_info)

rm(R_snp)

```

The columns of the `.Rvar` file include information on chromosome, variant name, position in base pairs, and the alternative and reference alleles. The `variance` column is the variance of each variant prior to standardization; this is required for PredictDB weights but not FUSION weights. PredictDB weights should be scaled by the variance before imputing gene expression. This is because PredictDB weights assume that variant genotypes are not standardized before imputation, but our implementation assumes standardized variant genotypes. If variance information is missing, or if weights are in PredictDB format but are already on the standardized scale (e.g. if they were converted from FUSION to PredictDB format), this scaling can be turned off using the option `scale_by_ld_variance=F` using the multigroup version of cTWAS (this option hasn't been based forward to the main branch yet). We've also include information on allele frequency in the variant info, but this is optional and not used by cTWAS.

The naming convention for the LD matrices is `[filestem]_chr[#].R_snp.[start]_[end].RDS`. cTWAS expects that all `.RDS` and `.Rvar` files in the directory contain LD information, so no other files with these suffixes should be in the directory. Each variant should be uniquely assigned to a region, and the regions should be left closed and right open, i.e. [start, stop). The positions of the LD matrices must match exactly the positions specified by the region file. Do not include invariant or multiallelic variants in the LD reference. 

We have provided the scripts used to generate the b38 LD reference in the package, as well a b37 LD reference, in the same directory. These scripts take `.pgen` files and regions as input and output the LD matrices and corresponding information:

```{r}

#path to b38 script
system.file("extdata/scripts", "convert_geno_to_LDR_chr.R", package = "ctwas")

#path to b37 script
system.file("extdata/scripts", "convert_geno_to_LDR_chr_b37.R", package = "ctwas")

```

On the University of Chicago RCC cluster, the b38 reference is available at `/project2/mstephens/wcrouse/UKB_LDR_0.1/` and the b37 reference is available at `/project2/mstephens/wcrouse/UKB_LDR_0.1_b37/`.

## Running cTWAS at a single locus

To speed computation in our single locus example, we will also subset the prediction models to only the genes at the HPR locus that we analyzed in the paper. Subsetting the prediction models is not strictly necessary (simply specifying a single region for the fine-mapping step will yield the same output), but subsetting the weights lets us avoid imputing all the genes during the imputation step. 

```{r}

#specify the genes to subset to:
gene_subset <-  c("CMTR2", "ZNF23", "CHST4", "ZNF19", "TAT", "MARVELD3", "PHLPP2", "ATXN1L", "ZNF821", "PKD1L3", "HPR" )

#subset to selected genes only
extra_table <-  extra_table[extra_table$genename %in% gene_subset,,drop=F]
weights_table <- weights_table[weights_table$gene %in% extra_table$gene,]

#subset the covariances
weight_info <- weight_info[weight_info$GENE %in% extra_table$gene,]

#write the .db file and the covariances
if (!file.exists("weights_nolnc/mashr_Liver_nolnc_subset.db")){
  db <- dbConnect(sqlite, "weights_nolnc/mashr_Liver_nolnc_subset.db")
  dbWriteTable(db, "extra", extra_table)
  dbWriteTable(db, "weights", weights_table)
  dbDisconnect(db)

  weight_info_gz <- gzfile("weights_nolnc/mashr_Liver_nolnc_subset.txt.gz", "w")
  write.table(weight_info, weight_info_gz, sep=" ", quote=F, row.names=F, col.names=T)
  close(weight_info_gz)
}

#specify the weight for the analysis
weight_subset <- "weights_nolnc/mashr_Liver_nolnc_subset.db"

```

We also included this final subset of liver prediction models in the cTWAS package.

```{r}
weight_subset <- system.file("extdata/weights_nolnc", "mashr_Liver_nolnc_subset.db", package = "ctwas")
```

### Imputing gene z-scores

Now that the input data is prepared, we are ready to impute gene z-scores using cTWAS. We will use the suset of prediction models that we prepared earlier, along with the LD matrix that we examined. We will also subset the GWAS z-scores to only the variants in this region:

```{r eval=F}

z_snp_subset <- z_snp[z_snp$id %in% R_snp_info$id,]

rm(R_snp_info)

saveRDS(z_snp_subset, file="/project2/xinhe/shared_data/ctwas_tutorial/gwas_summary_stats/ukb-d-30780_irnt_subset.RDS")

```

We've also included this file as part of the package:

```{r}

z_snp_subset <- readRDS(system.file("extdata/summary_stats", "ukb-d-30780_irnt_subset.RDS", package = "ctwas"))

```

To impute gene z-scores at this locus, we use the following code. Here, we use the option `harmonize_z = T` and `harmonize_wgt = T` to harmonize both the z-scores and the weights to the LD reference. Because the z-scores and the LD reference are from the same source (UK Biobank), we expect that the strand is consistent between the GWAS and LD reference, so we use the option `strand_ambig_action_z = "none"` to treat strand ambiguous variants as unambiguous. The prediction models are from a different population (GTEx), so we use the option `recover_strand_ambig_wgt` to recover strand ambiguous variants in the prediction models. The detailed procedure is described in the paper.

```{r}
outputdir <- "/project2/xinhe/shared_data/ctwas_tutorial/results/single_locus/"
outname <- "example_locus"
```


```{r, message=FALSE, results='hide', warning=FALSE}
dir.create(outputdir, showWarnings=F, recursive=T)

# get gene z score
res <- impute_expr_z(z_snp = z_snp_subset,
                     weight = weight_subset,
                     ld_R_dir = ld_R_dir,
                     outputdir = outputdir,
                     outname = outname,
                     harmonize_z = T,
                     harmonize_wgt = T,
                     strand_ambig_action_z = "none",
                     recover_strand_ambig_wgt = T)

```

The log is supressed in this tutorial. When running it, it tells us that there is only chromosome information for chromosome 16, as expected. For each chromosome, it also tells us that we've harmonized (flipped) the GWAS z-scores and weights, and that we've harmonized strand ambiguous variants for the weights. Chromsome 16 has 11 prediction models and all of them are successfully imputed. The warnings tell us that 21 of the chromosomes did not have any imputed genes.

We've now successfully harmonized the data and imputed the gene z-scores. The function has returned a list containing three objects: the imputed gene z-scores, the harmonized GWAS z-scores, and paths to `.expr.gz` files for each chromosome. We will store all three of these for use in the next step. Make sure to store the harmonized GWAS z-scores or this will introduce inconsistencies during the fine-mapping step.

```{r}
str(res)

z_gene_subset <- res$z_gene #imputed gene z-scores
ld_exprfs <- res$ld_exprfs #individual level imputed gene expression files
z_snp_subset <- res$z_snp #harmonized GWAS z-scores

save(z_gene_subset, file = paste0(outputdir, outname, "_z_gene.Rd"))
save(ld_exprfs, file = paste0(outputdir, outname, "_ld_exprfs.Rd"))
save(z_snp_subset, file = paste0(outputdir, outname, "_z_snp.Rd"))

```

In the directory, we have generated 4 files per chromosome during gene imputation. The `.expr.gz` files contain individual level imputed gene expression; these files are empty when using the summary statistics version of cTWAS but populated when using the individual level version of cTWAS. The `exprqc.Rd` files contain QC information about imputation for each gene. The `.exprvar` file contains position information for each imputed gene, including start positions and end positions; these positions are determined by the first and last variant positions for each gene prediction model. The `_ld_R_*.txt` file contains information about the LD regions and matrices used.


```{r}
list.files(outputdir, pattern="chr16")
```

### Fine-mapping with fixed parameters

After imputing gene z-scores, we are ready to run the cTWAS analysis. The full analysis involves first estimating parameters from the data, and then fine-mapping the genes and variants using these estimated parameters. This can be computationally intensive, so for this example, we will only run the fine-mapping step at the HPR locus, using the parameters we estimated in the paper.

Note that cTWAS expects the output of `impute_expr_z`. Currently, it is not possible to specify gene z-scores obtained using other software. This is because we cannot ensure that the LD reference used for imputation with other software is the same as the LD reference used for fine-mapping. This scenario would be fine for parameter estimation, which does not depend on LD, but it would be problematic for fine-mapping. 

```{r eval=F}

#the estimated prior inclusion probabilities for genes and variants from the paper
group_prior <- c(0.0107220302, 0.0001715896)

#the estimated effect sizes for genes and variants from the paper
group_prior_var <- c(41.327666, 9.977841)

# run ctwas_rss
ctwas_rss(z_gene = z_gene_subset, 
          z_snp = z_snp_subset, 
          ld_exprfs = ld_exprfs, 
          ld_R_dir = ld_R_dir, 
          ld_regions_custom = regions_file, 
          outputdir = outputdir, 
          outname = outname,
          estimate_group_prior = F,
          estimate_group_prior_var = F,
          group_prior = group_prior,
          group_prior_var = group_prior_var)

```

The log file tells us that cTWAS detected one region on chromosome 16, and no other regions on other chromosomes. cTWAS also added variant-by-gene and gene-by-gene correlation information ("R matrix info") for all regions, by chromosome; this is saved in a directory called `[outname]_LDR`. Finally, cTWAS ran a single iteration of SuSiE for all regions and reported the parameters used.

In the output directory, we've created a number of files. We've created the `[outname]_LDR` directory with the gene correlation information; this folder is not created if using genotype information instead of LD matrices.  The `[outname]_ld_R_*.txt` files contains information about the LD regions and matrices used. We also created two files related to region indexing, `[outname].regions.txt` and `[outname].regionlist.RDS`. 

The cTWAS results are in the `[outname].susieIrss.txt` file. This file has an entry for each gene and variant reporting the PIP  (`susie_pip`), its confidence set (`cs_index`), and its effect size (`mu2`). It also reports information on the confidence set (`cs_index`) that each gene or variant is assigned to. 

### Viewing the results

We will add the gene names to the results (the PredictDB weights use Ensembl IDs as the primary identifier), as well as the z-scores for each SNP and gene, and sort the result by the PIP:

```{r}

#load cTWAS results
ctwas_res <- read.table(paste0(outputdir, outname, ".susieIrss.txt"), header=T)

#load gene information from PredictDB
sqlite <- RSQLite::dbDriver("SQLite")
db = RSQLite::dbConnect(sqlite, weight_subset)
query <- function(...) RSQLite::dbGetQuery(db, ...)
gene_info <- query("select gene, genename, gene_type from extra")
RSQLite::dbDisconnect(db)

#add gene names to cTWAS results
ctwas_res$genename[ctwas_res$type=="gene"] <- gene_info$genename[match(ctwas_res$id[ctwas_res$type=="gene"], gene_info$gene)]

#add z-scores to cTWAS results
ctwas_res$z[ctwas_res$type=="SNP"] <- z_snp_subset$z[match(ctwas_res$id[ctwas_res$type=="SNP"], z_snp_subset$id)]
ctwas_res$z[ctwas_res$type=="gene"] <- z_gene_subset$z[match(ctwas_res$id[ctwas_res$type=="gene"], z_gene_subset$id)]

#display the results for the top 10 PIPs
ctwas_res <- ctwas_res[order(-ctwas_res$susie_pip),]
head(ctwas_res, 10)

```

To plot the results, we also want to update the gene positions. cTWAS assigns gene positions based on the first variant in the gene's prediction model, but we want to visualize gene locations using their transcription start site. First, we get gene information for all genes on chromosome 16 and subset to protein coding genes.

```{r, eval=F}

library(biomaRt)

#download all entries for ensembl on chromosome 16
ensembl <- useEnsembl(biomart="ENSEMBL_MART_ENSEMBL", dataset="hsapiens_gene_ensembl")
G_list <- getBM(filters= "chromosome_name", attributes= c("hgnc_symbol","chromosome_name","start_position","end_position","gene_biotype", "ensembl_gene_id", "strand"), values=16, mart=ensembl)

#subset to protein coding genes and fix empty gene names
G_list <- G_list[G_list$gene_biotype %in% c("protein_coding"),]
G_list$hgnc_symbol[G_list$hgnc_symbol==""] <- "-"

#set TSS based on start/end position and strand
G_list$tss <- G_list[,c("end_position", "start_position")][cbind(1:nrow(G_list),G_list$strand/2+1.5)]

save(G_list, file=paste0(outputdir, "G_list.RData"))

```

Now we update the position for each gene to the TSS.

```{r}

load(file=paste0(outputdir, "G_list.RData"))

#remove the version number from the ensembl IDs
ctwas_res$ensembl <- NA
ctwas_res$ensembl[ctwas_res$type=="gene"] <-  sapply(ctwas_res$id[ctwas_res$type=="gene"], function(x){unlist(strsplit(x, "[.]"))[1]})

#update the gene positions to TSS
ctwas_res$pos[ctwas_res$type=="gene"] <- G_list$tss[match(ctwas_res$ensembl[ctwas_res$type=="gene"], G_list$ensembl_gene_id)]

```

And we are now ready to plot the results at the HPR locus. There are some limited options to control the location of legends and labels, but making a publication-ready plot will probably require manual adjustment of these features. Note that the plot does not exactly match the figure in the paper because we are only using a subset of the variants in our example LD reference.

```{r}

#genome-wide bonferroni threshold used for TWAS
twas_sig_thresh <- 0.05/9881

ctwas_locus_plot(ctwas_res = ctwas_res,
                 region_tag = "16_1",
                 xlim = c(71.6,72.4),
                 ymax_twas = 85,
                 twas_sig_thresh = twas_sig_thresh,
                 alt_names = "genename",
                 legend_panel = "TWAS",
                 legend_side="left",
                 outputdir = outputdir,
                 outname = outname)

```

This plot function has an option include an empty space to add a gene track (`empty_gene_track=T`); however, the gene track must be plotted separately and manually aligned due to plotting incompatibilities between base R and the `Gviz` package. Here is an example that generates both the locus plot and the gene track, with the plot sizes that we used in the paper to manually align the plots.

```{r, eval=F}

#locus plot with empty space at the bottom for the gene track
pdf(file = paste0(outputdir, "HPR_locus_plot.pdf"), width = 5, height = 3.5)
plot_df <- ctwas_locus_plot(ctwas_res = ctwas_res,
                            region_tag = "16_1",
                            xlim = c(71.6,72.4),
                            ymax_twas = 85,
                            twas_sig_thresh = twas_sig_thresh,
                            alt_names = "genename",
                            legend_panel = "TWAS",
                            legend_side="left",
                            outputdir = outputdir,
                            outname = outname,
                            return_table = T,
                            empty_gene_track = T)
dev.off()

#gene track for the locus plot
pdf(file = paste0(outputdir, "HPR_locus_plot_genetrack.pdf"), width = 3.86, height = 0.6)
ctwas_locus_plot_genetrack(plot_df)
dev.off()

```

## Running cTWAS genome-wide

We now provide a workflow for the same analysis, but using the full data and estimating parameters. This can be computationally intensive. We performed these analyses with 10 cores and 56GB of RAM, although the exact resource requirements will vary with the numbers of genes and variants provided.

### Imputing gene z-scores

To impute gene z-scores genome-wide, we specify the full set of GWAS summary statistics, the full PredictDB liver weights, and the full set of LD reference matrices. This step can be slow, especially with both of the advanced harmonization options turned on. There is a parallelized version of this function in the `multigroup` branch of cTWAS. As specified here, imputation took approximately 6 hours, using a single core (the only option using the `main` branch). When getting started with your own data, it may be helpful to run `impute_expr_z` with both `recover_strand_ambig_wgt = F` and `strand_ambig_action_z = "none"` to make sure everything runs correctly, before turning on these features for the final analysis. 

```{r}

outputdir <- "/project2/xinhe/shared_data/ctwas_tutorial/results/whole_genome/"
outname <- "example_genome"

ld_R_dir <- "/project2/mstephens/wcrouse/UKB_LDR_0.1/"

dir.create(outputdir, showWarnings=F, recursive=T)

# get gene z score
if (file.exists(paste0(outputdir, outname, "_z_gene.Rd"))){
  ld_exprfs <- paste0(outputdir, outname, "_chr", 1:22, ".expr.gz")
  load(file = paste0(outputdir, outname, "_z_gene.Rd"))
  load(file = paste0(outputdir, outname, "_z_snp.Rd"))
} else {
  res <- impute_expr_z(z_snp = z_snp, 
                     weight = weight, 
                     ld_R_dir = ld_R_dir,
                     outputdir = outputdir, 
                     outname = outname,
                     harmonize_z = T, 
                     harmonize_wgt = T,
                     strand_ambig_action_z = "none", 
                     recover_strand_ambig_wgt = T)
  
  z_gene <- res$z_gene
  ld_exprfs <- res$ld_exprfs
  z_snp <- res$z_snp
  
  save(z_gene, file = paste0(outputdir, outname, "_z_gene.Rd"))
  save(ld_exprfs, file = paste0(outputdir, outname, "_ld_exprfs.Rd"))
  save(z_snp, file = paste0(outputdir, outname, "_z_snp.Rd"))
}

```

### Estimating parameters and fine-mapping

Now that we've imputed gene z-scores for the full genome, we are ready to run the full cTWAS analysis. The full analysis involves first estimating parameters from the data, and then fine-mapping the genes and variants using these estimated parameters. 

As mentioned previously, the full cTWAS analysis can computationally expensive, so we will specify several options to make the analysis faster. The `thin` argument randomly selects 10% of variants to use during the parameter estimation and initial fine-mapping steps, reducing computation. The `max_snp_region` sets a maximum on the number of variants that can be in a single (merged) region to prevent memory issues during fine-mapping. The `ncore` argument specifies the number of cores to use when parallelizing over regions.

```{r}

thin <- 0.1
max_snp_region <- 20000
ncore <- 6

```

We pass these arguments the `ctwas_rss` and run the full analysis. As specified, using 6 cores and with 56GB of RAM available, this step took approximately 7 hours.

```{r, eval=F}

# run ctwas_rss
ctwas_rss(z_gene = z_gene, 
          z_snp = z_snp, 
          ld_exprfs = ld_exprfs, 
          ld_R_dir = ld_R_dir, 
          ld_regions = "EUR",
          ld_regions_version = "b38",
          outputdir = outputdir, 
          outname = outname,
          thin = thin,
          max_snp_region = max_snp_region,
          ncore = ncore)

```


The files in the output directory are similar to the single locus example, but there are several additional files since we've performed parameter estimation. Parameter estimation involves two steps. The first step obtains a rough estimate for the parameters. These estimates are saved in the `*.s1.susieIrssres.Rd` file. The SuSiE output from the last iteration in this step is saved in `*.s1.susieIrss.txt`; this file contains the total number of variants analyzed by cTWAS, as used in PVE estimation, scaled by `thin`. The second step obtains a more precise estimate for the parameters using a subset of regions. These estimates are saved in the `*.s2.susieIrssres.Rd` file; the final entry of this file is the estimated parameters, scaled by the `thin` parameter. The `*.s2.susieIrss.txt` file contains the SuSiE output from the final iteration of this step. 

After parameter estimation, cTWAS performs a first pass at fine-mapping, using the proportion of variants specified in `thin`. These results are saved in the `*.s3.susieIrss.txt`. If `thin` is specified, then for regions with a gene having PIP greater than `rerun_gene_PIP`, cTWAS will make a final pass, analyzing these regions using the full set of variants. The final output of cTWAS is `*.susieIrss.txt`; this file contains results for all genes, all variants in regions with strong gene signals, and 10% of variants in other regions.
 
### Assessing parameter estimates

We provide code to assess the convergence of the estimated parameters and to compute the proportion of variance explained (PVE) by variants and genes.

```{r}

ctwas_parameters <- ctwas_summarize_parameters(outputdir = outputdir, 
                                               outname = outname, 
                                               gwas_n = gwas_n, 
                                               thin = thin)

#number of variants in the analysis
ctwas_parameters$n_snps

#number of genes in the analysis
ctwas_parameters$n_genes

#estimated prior inclusion probability
ctwas_parameters$group_prior

#estimated prior effect size
ctwas_parameters$group_prior_var

#estimated enrichment of genes over variants
ctwas_parameters$enrichment

#PVE explained by genes and variants
ctwas_parameters$group_pve

#total heritability (sum of PVE)
ctwas_parameters$total_pve

#attributable heritability
ctwas_parameters$attributable_pve

#plot convergence
ctwas_parameters$convergence_plot

```

### Viewing the results

As before, we will add the gene names to the results (the PredictDB weights use Ensembl IDs as the primary identifier), as well as the z-scores for each SNP and gene. We then show all genes with PIP greater than 0.8, which is the threshold we used in the paper.

```{r}

#load cTWAS results
ctwas_res <- read.table(paste0(outputdir, outname, ".susieIrss.txt"), header=T)

#load gene information from PredictDB
sqlite <- RSQLite::dbDriver("SQLite")
db = RSQLite::dbConnect(sqlite, weight)
query <- function(...) RSQLite::dbGetQuery(db, ...)
gene_info <- query("select gene, genename, gene_type from extra")
RSQLite::dbDisconnect(db)

#add gene names to cTWAS results
ctwas_res$genename[ctwas_res$type=="gene"] <- gene_info$genename[match(ctwas_res$id[ctwas_res$type=="gene"], gene_info$gene)]

#add z-scores to cTWAS results
ctwas_res$z[ctwas_res$type=="SNP"] <- z_snp$z[match(ctwas_res$id[ctwas_res$type=="SNP"], z_snp$id)]
ctwas_res$z[ctwas_res$type=="gene"] <- z_gene$z[match(ctwas_res$id[ctwas_res$type=="gene"], z_gene$id)]

#display the genes with PIP > 0.8
ctwas_res <- ctwas_res[order(-ctwas_res$susie_pip),]
ctwas_res[ctwas_res$type=="gene" & ctwas_res$susie_pip > 0.8,]

```

We will also visualize the POLK locus that we highlighted in the paper. As mentioned previously, the cTWAS output includes results for all genes, but it only includes a fraction of variants if the `thin` parameter is specified. There are complete variant results in regions with gene PIP greater than `rerun_gene_PIP`, but there are incomplete variant results in regions with weaker gene signals. The POLK locus is a "null" result; after running cTWAS, there is no strong gene signal. Thus, in order to plot the full set of variants at this locus, we must specify `rerun_ctwas=T` to run cTWAS again at this locus using all variants. This calls `ctwas_rss` and logs its progress; it also create a temporary folder within the output directory to store the results. After doing this the first time, you can set `rerun_load_only=T` to make changes to the plot without calling cTWAS again.

```{r eval=FALSE}

#genome-wide bonferroni threshold used for TWAS
twas_sig_thresh <- 0.05/sum(ctwas_res$type=="gene")

#show cTWAS result for POLK and store region_tag
ctwas_res[which(ctwas_res$genename=="POLK"),]
region_tag <- "5_45"

#plot the POLK locus
ctwas_locus_plot(ctwas_res = ctwas_res,
                 region_tag = region_tag,
                 xlim = c(75,75.8),
                 twas_sig_thresh = twas_sig_thresh,
                 alt_names = "genename",
                 legend_panel = "cTWAS",
                 legend_side = "left",
                 outputdir = outputdir,
                 outname = outname,
                 rerun_ctwas = T,
                 z_snp = z_snp,
                 z_gene = z_gene)
                 
```

### Cleaning up

The summary statistics version of cTWAS generates a lot of files. cTWAS added variant-by-gene and gene-by-gene correlation information ("R matrix info") for all regions in a directory called `[outname]_LDR`, and it also stored thinned version of the LD matrices in the same directory. We store all these files to speed computation, and we leave them unzipped at the end of the analysis so that they can be used with `ctwas_locus_plot`. However, once you are done with an analysis, we recommend zipping the contents of the `[outname]_LDR` folder.

```{r, eval=F}

system(paste0("tar -zcvf ", outputdir, outname, "_LDR.tar.gz ", outputdir, outname, "_LDR"))
system(paste0("rm -r ", outputdir, outname, "_LDR"))
                 
```